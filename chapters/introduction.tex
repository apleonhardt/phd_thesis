%************************************************
\chapter{Introduction}
\label{chp:introduction}
%************************************************

\section{Normative views of sensory neuroscience}

A core tenet of evolutionary theory is the idea that animals are in some sense adapted to their particular niche \citep{Darwin:1859aa}. This notion naturally extends to brains and specifically sensory systems. Ecological environments are not arbitrary; they exhibit statistical structure. The laws of physics, for instance, impose a level of regularity onto the set of possible sensory stimuli. Some such stimuli are more probable while others are outright incompatible with the rules that govern any given organism's surroundings. It is a reasonable supposition that nervous systems strive to determine the veridical state of the world based on noisy sensory data. \textit{A priori} assumptions about the way the world tends to be should then make this process more efficient and reliable. This essentially Bayesian approach to sensory systems enjoys a rich history, going back to Helmholtz who framed perception as the probabilistic problem of "unconscious inference" \citep{Helmholtz:1867aa}.

The evolutionary or teleological perspective is inherently normative. By assuming a natural environment and imposing purpose on a neural system, one may derive predictions about what properties a brain ought to have if it is to do its job effectively and efficiently. These predictions can then be tested experimentally. A central theme of my dissertation is the question to what extent natural visual statistics are reflected in the properties of neural circuitry, using fly motion vision as a model system.

\subsection{Statistics of natural images} Whether captured by eye or camera, natural images exhibit clear regularities that distinguish them from uniformly distributed noise.

\subsection{Information-theoretic approaches}

\subsection{Efficient coding} Animals evolve under manifold constraints \citep{Simoncelli:2001dn}. One of them is the need to detect stimuli that are survival-critical. Another is the need to perform this task using a minimum of metabolic energy. A third comes from the natural distribution of environmental features. The \textit{efficient coding hypothesis}, going back to \citet{Attneave:1954aa}, \citet{Barlow:1961aa}, and others, formalizes this approach to understanding biological sensors. Their theory was heavily influenced by the development of information theory which made a rigorous quantification of notions like channel capacity or redundancy feasible \citep{Cover:2006aa,Borst:1999hw}.

Efficient coding assumes that the goal of a sensory system is to represent as much relevant information as possible using the smallest feasible amount of resources. Selecting appropriate objective functions is, of course, fraught with difficulty. Ground truth constraints are generally not available and sensory organs often support a broad range of behavioral functions, each of which may necessitate a different definition of relevance. Nonetheless, the theory has successfully predicted features of real systems by assuming basic, tractable goals. In the sensory periphery, this usually takes the form of general preservation of information, thus maximizing the number of possible downstream use cases.

The main target of early vision then becomes reduction of redundancy. Ideally, signals carried by peripheral sensory neurons should be statistically independent in order to minimize wasteful duplication of information. Natural images exhibit regular statistics such as characteristically shaped power spectra that give rise to specific correlation structures. By removing such correlations and emphasizing deviations from expected natural statistics, an operation commonly termed whitening, early vision minimizes energy expenditure while conserving features of the stimulus that are presumed to be behaviorally relevant.

The fly retina provides classic demonstrations of this principle at work. \citet{Laughlin:1981wn} measured naturally occurring luminance distributions and compared the resulting histograms to corresponding response functions of lamina bipolar cells which form the first processing stage after the light-sensitive photoreceptor. In line with predictions from efficient coding, these response functions effectively equalized the histograms, making all outputs equally likely under the assumption of a natural stimulus distribution. A related study \citep{Srinivasan:1982uq} could show that lateral inhibition in the fly retina reliably removes the long-range correlations typical for natural images, effectively suppressing background, retaining sensitivity to small fluctuations, and implementing a type of predictive coding.

Constraint triples of this type---minimization of resources, maximization of transmitted information, assuming some naturalistic stimulus distribution---have been equally fruitfully applied to early processing in retina and visual cortex of mammals. Center-surround receptive fields in both retina and lateral geniculate nucleus (LGN) of the cat have been suggested to implement spatial filters that are well suited to whitening the typical power spectra of natural images \citep{vanHateren:1992aa,vanHateren:1993aa,Atick:1992aa}. \citet{Dan:1996aa} confirmed this prediction experimentally by recording LGN responses to natural movies, finding them to be largely statistically independent.

A closely related normative doctrine is that of sparse and distributed coding: the idea that sensory systems like visual cortex aim to represent natural stimuli using a minimum of active neurons. \citet{Ohlshausen:1996aa}, for instance, optimized a linear generative model to reconstruct natural images under the constraint of activation sparseness. The resulting filters bore striking resemblance to spatial receptive fields in area V1, indicating that early visual cortex is adapted to the task of efficiently representing real-world stimulus distributions.

\subsection{Task-driven optimization}
Efficient coding theory sidesteps the question of task relevance and presupposes that peripheral sensory systems perform lossless compression while maximizing efficiency. This has been a frequent source of criticism \citep{Simoncelli:2003aa}. After all, brains solve particular problems, so not all information is equal. Relevance may well depend on the particular nature of downstream processing or even behavioral state. For this reason alone, efficient coding is unlikely to scale to higher-level computation.

Instead of choosing a generic normative aim like information preservation, one may be able to do better by picking a specific, task-bound objective function.

Of course, for complex and highly multiplexed information processing systems like the brain, ascribing goals remains difficult. One may well be wrong about what a system is trying to achieve.

% Basic statistical properties
% Natural images are non-uniform 
% Luminance statistics
% FFT
% 1/f power spectra (Field, 1987)
% Correlations
% Barlow's efficient coding hypothesis
% Optimization work (ICA, Ohlshausen)
% Laughlin
% Dependency on ecology (van Hateren work, Dickinson ecology thing)
% Fitzgerald and stuff
% Figure: three images (Gaussian noise, 1/f noise, natural image)

% \section{ON and OFF pathways in sensory processing}

% \section{Motion vision in the fly}

% \subsection{Motion-guided behaviors}
% \subsection{Visual stimuli}
% \subsection{Algorithmic models}

% \section{Structure and function of the fly visual system}
% \subsection{Retina}
% \subsection{Lamina}
% \subsection{Medulla and lobula}
% \subsection{Lobula plate}
% \subsection{Downstream circuits}

% \section{Experimental tools in circuit neuroscience}
% \subsection{Neurogenetics}
% \subsection{Behavioral assays}
% \subsection{Electrophysiology}
% \subsection{Imaging techniques}
% \subsection{Connectivity analysis}

% \section{Concluding remarks}