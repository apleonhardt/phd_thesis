%************************************************
\chapter{Introduction}
\label{chp:introduction}
%************************************************

% Here, cite Dickinson (2014)
% Talk about D.\ melanogaster in general

% Explain optic flow somewhere

% Cite Exner p. 201
% Cite Schnell (2017)
% Cite von Uxkull
% Cite Dror
% Cite Francescini
% Cite van Hateren, 2005
% Cite Trenholm, 2011 in retina
% Cite that Plos Biol paper about photoreceptors...
% Cite new Dickinson stuff

\section{Normative views of sensory neuroscience}

A core tenet of evolutionary theory is the idea that animals are in some sense adapted to their particular niche \citep{Darwin:1859aa}. This notion naturally extends to brains and specifically sensory systems. Ecological environments are not arbitrary; they exhibit statistical structure. The laws of physics, for instance, impose a level of regularity onto the set of possible sensory stimuli. Some such stimuli are more probable than others while certain configurations are outright incompatible with the rules that govern any given organism's surroundings.

It is a reasonable supposition that nervous systems strive to determine the veridical state of the world based on noisy sensory data, insofar as it supports a given behavioral program. \textit{A priori} assumptions about the way the world tends to be should then make this process more efficient and reliable. This approach to sensory systems enjoys a rich history, going back to Helmholtz who framed perception as the probabilistic problem of "unconscious inference" \citep{Helmholtz:1867aa}. It is closely connected to Bayesian theories of sensing but operates on much longer, evolutionary time scales \citep{Doya:2007aa}.

The evolutionary or teleological perspective is inherently normative. From a combination of purpose and environment, one can derive predictions about what properties the system ought to have if it is to fulfill its purpose effectively and efficiently. These predictions can then be tested experimentally. As such, it complements the purely descriptivist perspective on neural perceptual machinery which heavily relies on simplified, tractable inputs. A central theme of my dissertation is the question to what extent natural visual statistics are reflected in the properties of neural circuitry, using fly motion vision as a model system. The following section provides some relevant background.

\subsection{Statistics of natural visual scenes} Understanding the natural stimulus distribution is fundamental to normative approaches in sensory neuroscience. Given the topic at hand, this section focuses on natural visual stimuli. Whether captured by eye or camera, natural images exhibit clear regularities that set them apart from uniformly distributed noise. Realistic images thus represent only a small subset of all possible pixel configurations.

This is easily visualized by manipulating pictures in Fourier space \citep{Hyvarinen:2009hf}. Unaltered images exhibit edges, gradients, homogeneous textures, and segregated objects. These typical features also extend to natural video sequences. Randomizing the phase structure of images scrambles their higher-order structure and yields phenomenologically atypical textures, even though the manipulation conserves second-order statistics as a consequence of the natural amplitude spectrum. Nonetheless, local patches may well resemble real image features. Finally, when one flattens the image's frequency spectrum, unambiguously artificial noise remains. Critically, at each stage we can clearly distinguish between images that fall within or outside the distribution of natural visual scenes.

% FIGURE!!!

Large corpora of calibrated natural scene images like the ones generated by \citet{vanHateren:1998jt} or \citet{Tkacik:2011aa} make it possible to characterize fundamental statistical properties. Below, I describe a subset of relevant features, ranging from first-order parameters to more complex traits.

\subsubsection{Luminance}

As a first step, one can measure the distribution of pixel luminance. After per-image normalization, linearly scaled luminance values in natural images are typically positively skewed \citep{Brady:2000aa,Laughlin:1981wn,Geisler:2008gu}. That is, pixels that are dark relative to average luminance numerically outweigh bright ones. When put on a logarithmic scale, this results in a symmetric distribution. The finding applies universally to image sets across a multitude of environments. Presumably, the skewness follows from basic physical principles.

\subsubsection{Contrast}
Another fundamental statistic is local contrast. Its quantification is less straightforward than in the case of luminance as it requires assumptions about the sensory system and the stimulus under investigation. Common definitions are the difference between feature and background luminance divided by the latter (so-called Weber contrast), the standard deviation of normalized luminance in a small image patch (so-called root-mean-squared contrast), or the difference of luminance extrema normalized by their sum (so-called Michelson contrast, often applied to wide-field stimuli).

Alternatively, in analogy to processing in retinal ganglion cells, contrast can be modeled as the response of divisively normalized center-surround receptive fields. Here, a similar asymmetry as for luminance emerges: At all spatial scales, natural images contain more dark (OFF) than light (ON) contrast \citep{Ratliff:2010kb,Cooper:2015in}. This is a direct consequence of the positively skewed luminance distribution. Luminance and contrast are not fully independent: their correlation is small but clearly negative \citep{Geisler:2008gu}.

\subsubsection{Spatial patterns}
Spatial structure represents one of the most informative aspects of any scene. A hallmark of natural images is the shape of their Fourier amplitude spectra \citep{Geisler:2008gu}. The average contribution of component frequencies falls with frequency and is well modeled by the function $1/f^n$ with $n\approx1.0$ \citep{Ruderman:1994ty,Field:1987ua,Dyakova:2015dy}. As a consequence, natural images are approximately scale-invariant; zooming in or out does not substantially affect the shape of the Fourier spectrum. Interestingly, the pink noise model also reproduces spatial properties of local patches in naturalistic video sequences \citep{Dong:1995aa} even though the complex statistics of animal movement make the task of gathering ecologically relevant stimuli difficult.

As discussed above, pink Gaussian (or $1/f$) noise serves as a reasonable local approximation to realistic images but falls short in several ways. One of them is a linearly symmetric luminance distribution which does not reproduce natural skew \citep{Geisler:2008gu}. Moreover, it fails to model the heavy-tailed response properties of arbitrary receptive fields scanning natural scenes \citep{Field:1987ua}. Clearly, the Fourier spectrum does not provide an exhaustive description of real-world spatial features. Natural images show pronounced co-linearity, parallel contours, sharp transitions, and many other forms of spatial regularity that go beyond simplistic second-order features.

\subsubsection{Other features}
In addition to the most salient subset of features outlined above, researchers have mapped the natural statistics of many additional image properties. They include depth \citep{Huang:2000aa}, color \citep{Ruderman:1998aa,Wachtler:2001aa}, and optic flow \citep{Roth:2005aa,Roth:2007bg}, but are often limited in throughput by the available measurement devices and sensors \citep{Geisler:2008gu}. Reliable estimation of natural statistics in high-dimensional spaces requires sufficient volumes of data. For this reason, static but large image databases have been an important foundation for research in the space \citep{vanHateren:1998jt}.

\subsubsection{Visual ecology}
To relate any visual system to naturally occurring stimuli, a reasonable approximation of the neuro-ecologically relevant image distribution is required. Available natural scene libraries are biased toward human visual surrounds when it comes to choice of environment, perspective, focal length, resolution, and other parameters \citep{Tkacik:2011aa}. Many of these qualities are at odds with the experience of a typical fruit fly. For instance, the \textit{Drosophila} eye processes scenes at the comparatively low resolution of approximately $25 \times 25$ facets or "pixels", covering almost $180\degree$ of azimuth at a separation of $\approx5\degree$ \citep{Borst:2009gv}. The spatial acuity of the fly eye is thus orders of magnitude below that of its human counterpart. Moreover, not much is known about the ground-truth visual statistics of the environment in which \textit{Drosophila} initially evolved \citep{Dickinson:2014aa}.

%Not a problem because scale invariance.
Spatial differences between typical inputs, however, are attenuated by the aforementioned invariance of realistic image amplitude spectra. Generally, drosophilids are extremely widespread and resilient organisms. Their brains possess comparatively few neurons, resulting in limited degrees of freedom. As a consequence, visual adaptation is unlikely to be deeply environment-specific \citep{Dickinson:2014aa}. Finally, many of the lower-order statistics discussed above appear to be due to fundamental properties of the world and therefore generalize to visual environments across the board \citep{Geisler:2008gu,Simoncelli:2001dn}. \citet{vanHateren:1997vg}, for instance, studied fly retinal processing but gathered natural visual time series data simply by walking through a forest while recording the output of a LED attached at human eye level.

\subsection{Information theory}

% CHECK WHAT YOU CAN CITE FROM THE 2000s

Information theory, a branch of probability theory initially developed in the context of electrical communication channels \citep{Shannon:1948aa}, provides powerful techniques for studying neural and particularly sensory processing \citep{Borst:1999hw}.

The activity of visual sensory neurons is generally related to some parameter of a given stimulus. In the case of motion-selective units, this could include direction, velocity, acceleration, or contrast. Classically, experiments probe possible relationships by systematically varying parameters and recording stimulus-response curves to determine what feature of the visual input is encoded. When considering the function of neural circuits, however, precision of encoding also matters: we want to quantify rigorously not just what but also how much stimulus-related information a sensory cell carries. Information theory offers a principled way of studying relationships of this type by measuring the reduction in uncertainty about the stimulus any given neural signal provides.

Formally, this is achieved by determining the entropy $H$ of appropriate distributions and closely related to ideal-observer models of decoding. Consider a simple experiment in which the responses of direction-selective neurons are measured as a function of a specific stimulus feature like pattern velocity. Such measurements are stochastic, so we take stimulus and response to be random variables $S$ and $R$ with associated probability distributions. We can quantify our uncertainty about a variable by calculating the Shannon entropy
\begin{equation}
    H(X) = - \sum_{i} p(x_i) \log_2 p(x_i) \geq 0
\end{equation}
in which $i$ indexes all possible discrete outcomes $x$ of $X$ and $p(x)$ denotes the probability of $x$ occurring \citep{Cover:2006aa}. For the logarithm with base two, entropy is measured in bits.

Intuitively, information rigorously measures how much an ideal observer learns about the stimulus from the neuron's response. This intuition can be made precise by expressing the quantity as a difference between full stimulus entropy and entropy left after observing the response
\begin{equation}
    I(R; S) = H(S) - H(S|R).
\end{equation}

This quantity is called mutual information between $R$ and $S$ \citep{Cover:2006aa}. From its definition, we can readily see that the measure is either positive if something is learnt, or exactly zero if knowing the response does not reduce uncertainty about the stimulus at all (in which case $H(S) = H(S|R)$). This occurs whenever $R$ and $S$ are statistically independent, and thus lines up with experimental intuition.

By expanding the expression above, we can calculate the information about a certain stimulus condition $s_x$ provided by the neuron's response $R$ as
\begin{equation}
    I(R; s_x) = \sum_{i} p(r_i | s_x) \log_2 \frac{p(r_i | s_x)}{p(r_i)}
\end{equation}
where $i$ indexes the set of all enumerated responses, $p(r_i)$ denotes the marginal probability of a specific response across all stimulus conditions, and $p(r_i | s_x)$ denotes the response probability conditioned on a specific stimulus \citep{Borst:1999hw}. Average information for the full stimulus set is then computed as the probability-weighted sum of specific per-stimulus information
\begin{equation}
    I(R; S) = \sum_{j} p(s_j) I(R, s_j)
\end{equation}
which comes out as the mean if stimuli are equally probable (as is the case in stimulus-balanced designs).

Note that information as defined here critically depends on decisions like response binning and the choice of stimulus conditions. In a sense, values hinge on the choice of alphabet used to represent the experiment.

For some designs, one can derive theoretical bounds on the transmission capacity of neural channels and estimate normative qualities like the efficiency of a neural code by weighing transmitted information against maximally possible response entropy. It also extends naturally to the encoding of dynamic stimuli. Information theory is a universal method. It works in the absence of a specific response model and without making strong assumptions about the function of a sensory system or the constraints under which it operates.

The technique has been used to quantify information rates, coding efficiency, and transmission bounds for several model systems including motion-sensitive neurons in flies \citep{Bialek:1991aa,vanSteveninck:1997aa,Haag:1998wr,Weber:2012dr}, electroreceptors in fish \citep{Wessel:1996aa}, and retinal ganglion cells in the salamander \citep{Warland:1997aa}. Remarkably, measured information rates depend on the choice of stimulus ensemble. In frog auditory neurons, for instance, \citet{Rieke:1995aa} found efficiency values close to 90\% when they tested on naturalistic input.

\subsection{Efficient coding}
Sensory systems evolve under a multitude of constraints \citep{Sterling:2015aa}. One of them is the need to detect stimuli that are survival-critical. Another is the need to perform this task using a minimum of metabolic energy. A third comes from the natural distribution of environmental features. The \textit{efficient coding hypothesis}, going back to \citet{Attneave:1954aa}, \citet{Barlow:1961aa}, and others, formalizes this approach to understanding biological sensors. Their theory was of course heavily influenced by the development of information theory which made a rigorous quantification of notions like channel capacity and redundancy feasible \citep{Cover:2006aa,Borst:1999hw}.

Efficient coding assumes that the goal of a sensory system is to represent as much relevant information as possible using the smallest feasible amount of resources. Selecting appropriate objective functions is, of course, fraught with difficulty. Ground truth constraints are generally not available and sensory organs often support a broad range of behavioral functions, each of which may necessitate a different definition of relevance. Nonetheless, the theory has successfully predicted features of real systems by assuming basic, tractable goals. In the sensory periphery, this usually takes the form of general preservation of information, thus maximizing the number of possible downstream use cases.

The main target of early vision then becomes reduction of redundancy. Ideally, signals carried by peripheral sensory neurons should be statistically independent in order to minimize wasteful duplication of information. Natural images exhibit regular statistics such as characteristically shaped power spectra that give rise to specific correlation structures. By removing such correlations and emphasizing deviations from expected natural statistics, an operation commonly termed whitening, early vision minimizes energy expenditure while conserving features of the stimulus that are presumed to be behaviorally relevant.

The fly retina provides classical demonstrations of this principle at work. \citet{Laughlin:1981wn} measured naturally occurring luminance distributions and compared the resulting histograms to corresponding response functions of lamina bipolar cells which form the first processing stage after the light-sensitive photoreceptor. In line with predictions from efficient coding, these response functions effectively equalized the histograms, making all outputs equally likely under the assumption of a natural stimulus distribution. A related study \citep{Srinivasan:1982uq} could show that lateral inhibition in the fly retina reliably removes the long-range correlations typical for natural images, effectively suppressing background, retaining sensitivity to small fluctuations, and implementing a type of predictive coding.

Constraint triples of this type---minimization of resources, maximization of transmitted information, assumption of some naturalistic stimulus distribution---have also been applied fruitfully to early processing in retina and visual cortex of mammals. Center-surround receptive fields in both retina and lateral geniculate nucleus (LGN) of the cat have been suggested to implement spatial filters that are well suited to whitening the typical power spectra of natural images \citep{vanHateren:1992aa,Atick:1992aa,vanHateren:1993aa}. \citet{Dan:1996aa} confirmed this prediction experimentally by recording LGN responses to natural movies, finding them to be largely statistically independent. \citet{Ratliff:2010kb} argue that the asymmetry in ON and OFF contrast prevalence mentioned above explain the difference in numbers between ON and OFF retinal ganglion cells in the vertebrate retina. Interestingly, evidence from primary sensory neurons in V1 of awake mice indicates that adaptation to natural scene statistics partially depends on experience; if raised in stimulus-deprived environments, predictive coding of specifically real images is abolished \citep{Pecka:2014aa}.

A closely related normative doctrine is that of sparse and distributed coding: the idea that sensory systems like visual cortex aim to represent natural stimuli using a minimum of active neurons \citep{Simoncelli:2001dn}. \citet{Ohlshausen:1996aa}, for instance, optimized a linear generative model to reconstruct natural images under the constraint of activation sparseness. The resulting filters bear striking resemblance to localized oriented bandpass receptive fields in area V1, indicating that early visual cortex is adapted to the task of efficiently representing real-world stimulus distributions \citep[for a related method, based on independent component analysis, see][]{vanHateren:1998jt,Bell:1997ve}.

\subsection{Task-centric approaches}
Efficient coding theory sidesteps the question of task relevance and presupposes that peripheral sensory systems perform lossless compression while maximizing efficiency. This has been a frequent source of criticism \citep{Simoncelli:2003aa}. After all, brains solve particular problems, so not all information is equal. Relevance may well depend on the particular nature of downstream processing or even behavioral state. For this reason alone, efficient coding is unlikely to scale to higher-level computation.

Instead of choosing a generic normative aim like information preservation, one may be able to do better by picking a specific, task-bound objective function. Encouraging examples come from recent advances in artificial pattern recognition \citep{Bishop:2006aa} and specifically the hierarchical models prevalent in so-called deep learning \citep{Goodfellow:2016aa}. Response properties along the visual cortical pathway go from simple local receptive fields in V1 to object-specific and invariant representations in higher areas \citep{Felleman:1991aa,Yamins:2016hg}. Such neurons are sensitive to, for instance, cars regardless of perspective. Hierarchical neural networks that mimic aspects of this organization \citep{Fukushima:1980ve} have reached human-like performance on large object recognition data sets, made possible by advances in optimization techniques \citep{LeCun:1989aa} and raw processing power \citep{LeCun:2015dt}. \citet{Yamins:2014gi} modeled an artificial deep network after the primate object recognition cascade consisting of areas V1, V2, V4, and IT. After training this system to recognize classes of objects in natural images, they compared learned weights with representations in the biological system and found striking similarities, at least in higher layers \citep{Cadieu:2014in}. More generally, early stages of visually trained deep networks often exhibit receptive fields that resemble those found in the vertebrate retina or V1 \citep{Yamins:2016hg}.

In psychophysics, studies have successfully predicted texture salience from statistical properties of natural images \citep{Tkacik:2010aa,Hermundstad:2014aa}. By determining maximally informative features in real stimuli, it was possible to predict behavioral performance for a given synthetic texture.

Task-driven approaches have also been applied to the visual system of the fly. \citet{Clark:2014aa} and \citet{Fitzgerald:2015aa} optimized a motion detector to maximize the linear correlation between time-averaged model output and true velocity of rigidly translating natural images. While functionally plausible, this makes strong assumptions about the true goal of motion-sensing elements and evolutionary pressures at work. Other studies put the fly optomotor response in its functional context by evaluating course stabilization in closed-loop, which is the supposed functional target for wide-field motion responses. However, this work did not take the natural stimulus distribution into account but used artificial stimuli instead \citep{Warzecha:1996bm,Warzecha:1998tn}.

Combining behaviorally relevant targets with biologically plausible models appears to be a promising tool for understanding neural processing beyond the sensory periphery. Of course, for complex and highly multiplexed information processing systems like the brain, ascribing goals remains challenging: one may well be wrong about what any given circuit is in fact trying to achieve. Additionally, the approach critically depends on the choice of model---say, a feedforward network for cortical processing as opposed to a more plausible recurrent design---and the techniques used for post-hoc comparisons between model and neural circuit \citep{Yamins:2016hg}.

% Bialek H1 thing-y
% van Hateren work

% Dependency on ecology (van Hateren work, Dickinson ecology thing)
% Figure: three images (Gaussian noise, 1/f noise, natural image)

% \section{ON and OFF pathways in sensory processing}

\section{Motion vision in the fruit fly}
% Mention D.\ melanogaster

\subsection{Stimulus design}
% % System identification: gratings (work horse)
% % Noise (Frye? Clark? Weber?)
% % Apparent motion
% % Reverse-phi
% % Glider
% % Natural (Straw, O'Carroll, Laughlin-Dror, Nordstrom 2008)

\subsection{Visually guided behaviors}
Flies and specifically \textit{D.\ melanogaster} exhibit a largely stereotyped, well characterized repertoire of visually driven behaviors \citep{Borst:2014kl}.
% BETTER CITATION
This has greatly contributed to their ongoing popularity in the field of motion vision. Reflexive responses facilitate the precise measurement of sensory input-output relationships in large volumes. Systems neuroscience derives predictions about neural processing from quantitative descriptions of behavior which drive physiological work. In turn, behavioral tasks provide powerful high-throughput test beds for hypotheses generated from mapping neural circuits.

A vast majority of behaviors is not explored in the ecological context of freely moving animals but under strictly controlled conditions instead. Deviations from naturalness include head-fixation, tethering, artificial visual stimulation, and synthetic stimulus statistics. Experimental abstraction allows for full control of sensory stimuli and exact observation of fly movements. However, it also runs the risk of mapping artificial behavioral motifs that do not generalize to ecological settings \citep{Krakauer:2017aa}. The controlled approach and in particular the reliable optomotor response have nonetheless shed significant light on the inner workings of motion detection circuitry in flies.

Behavioral assays were a critical component of my work in the studies that comprise the thesis at hand. In the following section, I survey the range of visual reflexes with a clear focus on \textit{Drosophila}, referring to other commonly employed fly genera (like \textit{Musca} or \textit{Calliphora}) where instructive.

% Make a note about new free walking approaches (Branson)

\subsubsection{Optomotor response}
Flies follow the visual motion of their surround. When for instance tethered to the center of a rotating textured drum, they reflexively attempt to turn in the same direction. This behavioral pattern is termed optomotor response and was a popular model behavior even in early sensory \textit{Drosophila} ethology \citep{Hecht:1934aa,Kalmus:1943aa}.

A seminal quantitative investigation of the response was performed by \citet{Hassenstein:1956fa}. They placed \textit{Chlorophanus viridis} on a spherical Y-maze that was light enough to be held and moved by the beetle, thereby simulating walking while keeping the animal fixed relative to the stimulus. Then, by counting leftward versus rightward choices as a function of various parameters of a motion stimulus, they were able to estimate turning tendency in a graded fashion. Their quantitative findings formed the foundation of the algorithmic Hassenstein-Reichardt model for insect optomotor behavior \citep{Reichardt:1961aa}, which is discussed in more detail below.

The optomotor response is not exclusive to one mode of locomotion. It can be demonstrated in tethered flying \textit{Drosophila}, measured via torque meter or as the difference between wing beat frequencies, as well as in flies walking on treadmill systems \citep{Buchner:1976kd,Gotz:1964bj,Fermi:1963aa,Goetz:1973aa}. While commonly elicited by yaw motion revolving around the vertical body axis of the fly, it generalizes to pitch and roll \citep{Blondeau:1982hd}. When the fly's head is left unrestrained, its movements also track stimulus direction \citep{Hengstenberg:1988kg,Haikala:2013cm}.

A plethora of studies has mapped stimulus-dependencies of the optomotor response \citep[see][]{Borst:2010fk}. Critically, the behavior is not driven by the true rotational velocity of the visual pattern. Instead, many other motion features influence response amplitudes. The most salient properties can be summarized as follows:

\begin{enumerate}
    \item Flies turn in the same direction as the pattern.
    \item Stimulus geometry has a strong effect on the velocity tuning. For sine gratings, increasing the pattern wavelength $\lambda$ shifts the curve towards larger velocities $v$. Critically, the fly optomotor response is tuned not to stimulus velocity but to contrast frequency instead, which is given by $f = \frac{v}{\lambda}$.
    \item Responses are ambiguous with regard to frequency and only proportional in a limited range. They initially grow with temporal frequency, but show a clear optimum after which turning decreases again. In \textit{Drosophila}, measurements of this peak frequency exhibit significant variability but are in the range of \SIrange{1}{10}{\hertz} \citep{Gotz:1964bj,Duistermars:2007aa}.
    \item Optomotor responses are subject to spatial aliasing. If $\lambda$ drops below the Nyquist limit of twice the receptor distance, the response inverts due to undersampling of the sine grating. From this, one can estimate the \textit{Drosophila} sampling base as $\approx \SI{4.6}{\degree}$ of visual space, which matches average inter-ommatidial distance well \citep{Gotz:1964bj}.
    \item The magnitude of the response increases with stimulus contrast.
\end{enumerate}

% FUNCTION AND OTHER SPECIES

Functionally, the reflex is usually interpreted as a compensatory steering mechanism \citep{Heisenberg:1984aa}. Flies are capable of long-duration flight in adverse surroundings \citep{Dickinson:2014aa}. They also perform acrobatic maneuvers whose instantaneous rotational velocity may well exceed \SI{2000}{\degree\per\second} during unrestrained flight, all at forward speeds that can reach \SI{0.7}{\metre\per\second} in larger species \citep{Land:1974dp,Mronz:2008eb}. At the same time, the weight of an individual fruit fly is on the order of \SI{0.2}{\milli\gram} \citep{Seiger:1966a}. This makes them preciously vulnerable to external perturbations like sudden gusts of wind. Internal sources of noise, like small asymmetries in wing morphology, add to the problem.

% Kalmus
% Goetz (1975)
% Warzecha?
% Better treatment of equilibrium

In concert with proprioceptive mechanisms, the optomotor response confers some protection against unintended path deviations. Any turning response that is syndirectional with global optic flow will eventually return the fly to straight heading, assuming that the estimated optic flow provides an accurate read-out of ego-motion. The optomotor response implements a simple, reflexive feedback system that keeps the fly on course\footnote{Note that some studies have suggested that \textit{Drosophila} is capable of modulating the strength and even sign of optomotor orientation through stochastic adjustment and subsequent evaluation of visual feedback \citep{Wolf:1992aa,Wolf:1986ii}.} \citep{Borst:2014kl}. In this vein, some authors have argued that the non-monotonous velocity tuning of the motion sensor keeps the system from going into irrecoverable oscillations \citep{Warzecha:1996bm}. Comparable locomotor reflexes are found in other insects and fish \citep{Arnold:1974aa}, and the optomotor response closely resembles the widespread optokinetic reflex that stabilizes the eye during movement.

% FIND BETTER CITATION FOR ORGER

Traditionally, optomotor responses have been studied in tethered animals. If the functional logic outlined above holds, then it should also be possible to observe a visually induced following reflex in unrestrained behavior. Counter-intuitively, \citet{Goetz:1970aa} found that groups of fruit flies placed in a rotating drum moved against the direction of the wall pattern. This was later successfully explained as a consequence of complex superpositions of external stimulus and self-induced translating optic flow \citep{Goetz:1975aa}. \citet{Strauss:1997ut} used on-line tracking and live generation of appropriate stimuli to suppress self-generated feedback and confirmed tethered turning behavior in free walking. While tracking flying flies in a large arena, \citet{Mronz:2008eb} could elicit prolonged curved trajectories and largely suppress the body saccades typical for \textit{Drosophila} flight by rotating the cylinder's texture.

% Other species cognates

\subsubsection{Landing and escape response}
Flies are notoriously capable at evading fast-moving objects and rarely collide with static landmarks. Motion sensors signal imminent collisions through particular patterns of translational optic flow. Approaching a textured surface results in visual expansion whose magnitude correlates with distance and thus, critically, time to impact \citep{Koenderink:1986um}. By selectively extracting looming flow fields, flies can trigger the appropriate response. When at rest, they initiate a fast and largely stereotyped escape. When flying, they either evade or perform the wing and leg adjustments required for safe landing \citep{Borst:2014kl}.

Several studies have investigated the latter condition in tethered experimental settings. For laterally expanding square-wave gratings, \textit{Drosophila} robustly steer away from the focus of expansion \citep{Tammero:2002aa}. Centered expansion, on the other hand, activates a landing sequence. \citet{Duistermars:2007aa} systematically compared the tuning properties of expansion-triggered evasion and rotation-triggered optomotor response. The two pathways differed in pooling and contrast sensitivity, yet, aspects like temporal and spatial sensitivity were strikingly similar. This indicates that both behaviors draw from the same set of motion-sensitive units which are then processed differentially.

Centrally positioned expansion of sine or square-wave gratings prompts the landing response, which consists of a fixed sequence of postural and steering-related adjustments \citep{Braitenberg:1966aa,Goodman:1960aa,Borst:1986wx}. Critically, the delay leading up to initiation of this program depends on spatial and temporal aspects of the expanding stimulus. By manipulating these parameters, \citet{Bahde:1986eh} demonstrated that a single set of motion detecting units could feasibly underlie both optomotor and landing response in the housefly \textit{M.\ domestica}. Their model simply integrates motion signals up to a certain threshold, after which the landing sequence is started. This system was capable of reliably predicting response latencies.

When at rest, flies respond to fast expansion by rapidly initiating a controlled jump. This happens within $\approx\SI{200}{\milli\second}$ of stimulus onset and is not completely stereotyped. In a majority of cases, flies manage to coordinate their take-off such that they escape away from the looming stimulus, which hints at a surprisingly elaborate transformation from visual input to motor output \citep{Card:2008aa}. Recent high-resolution tracking of escape responses revealed a subtly bimodal distribution of time courses, indicating two distinct, stimulus-dependent escape programs and thus even more complex behavioral phenomenology \citep{Reyn:2014aa}. Intriguingly, \citet{Muijres:2014aa} tracked the flight kinematics of looming-triggered escape responses in freely flying \textit{D.\ melanogaster} and observed extremely rapid banked turns consisting of carefully calibrated turns and counter-turns. This presumably survival-critical sequence is completed within a small number of wing beats, and testament to the impressive maneuverability of fruit flies.

\subsubsection{Beyond optic flow}
All behaviors discussed so far were derived from global optic flow. Of course, the visual environment of the fruit fly provides cues beyond wide-field motion.

A prominent example among them is fixation. Ego-motion results in the largely coherent flow fields that span the complete visual field and drive the optomotor response. Superimposed onto this motion background are the relative movements of nearby objects. Flies need to track such entities in order to avoid predators, find conspecifics, and navigate between landmarks.

This can be studied experimentally. Depending on the separation of two bars projected onto the wall of an arena, walking flies either track the area between the two stripes or choose one of two as they grow more distant \citep{Horn:1975aa}. \citet{Maimon:2008go} studied fixation behavior in freely flying \textit{Drosophila} and discovered a remarkable trade-off between approach and avoidance by varying the height of a rod placed in an arena. When the bar was long, flies would approach and circle it. When it was shortened, the bar became aversive; flies now tended to steer clear of the object. The behavioral pattern is reminiscent of a famous behavioral setting, Buridan's paradigm\footnote{The set-up is aptly named after a thought experiment attributed to the French priest and philosopher Jean Buridan. In it, an equally hungry and thirsty donkey is eternally stuck between food and water, eventually starving to death \citep{Knowles}.} \citep{Buelthoff:1982aa}. In a behavioral chamber with two vertical rods flies will ceaselessly walk from one to the other, entering a seemingly inescapable loop between fixation and anti-fixation.

Experiments in tethered flies have illuminated some functional aspects of the fixation response. \citet{Reichardt:1969aa} coupled the output of a torque meter to the position of a vertically elongated bar, which enabled the fly to control its visual input in a semi-realistic closed-loop setting. Interestingly, \textit{M.\ domestica} kept the target in an, on average, frontal position. \citet{Reichardt:1973aa} ascribed this behavior to an asymmetric motion response. In an open-loop setting, a black stripe moving from front to back resulted in a stronger optomotor response than its back-to-front counterpart. In closed-loop this imbalance would eventually push the stripe toward the front. In later theoretical treatments of fixation and orienting behavior, the imbalance was analyzed as the superposition of a optomotor-like response and the response of a position system that determines the position of a salient cue and orients the fly towards it \citep{Poggio:1973aa}. Relatedly, \citet{Pick:1974aa} argued that flies simply track flicker. Recent work used neurogenetic silencing techniques to isolate motion- from position-driven responses and found evidence for a position system of the predicted type in \textit{D.\ melanogaster} \citep{Bahl:2013ha}.

Fruit flies exhibit various other visual responses. \citet{Bahl:2015cqa} have recently provided evidence that \textit{Drosophila} respond robustly to temporally modulated spatial contrast. The functional significance of this sensitivity, however, remains unclear. In an early piece of sensory ethology, \citet{Carpenter:1905aa} described the tendency of a \textit{Drosophila} species to approach light. This is an example of phototaxis, one of the most simplistic visual reflexes in the animal kingdom.

On the more sophisticated end of the spectrum, studies have shown that fruit flies utilize the polarization of light to orient their course \citep{Weir:2012aa}. Polarized light results from atmospheric scattering as well as certain reflecting surfaces, and provides critical navigational cues. The information is mediated by two physiological pathways, one sensitive to dorsal polarization emanating from the sky and the other to ventral reflectance-derived stimuli \citep{Wernet:2012aa}. The system may explain the reported long-term navigation feats of certain \textit{Drosophila} species, which have been reported to travel up to $\SI{10}{\kilo\metre}$ in the desert \citep{Dickinson:2014aa}.

Finally, fruit flies possess a limited repertoire of color-mediated behaviors \citep{Menne:1977aa}. However, this is limited to coarser types of visual sensing. For instance, flies learn to differentiate green and blue in an aversive association task \citep{Schnaitmann:2013aa}. The optomotor response, on the other hand, operates with luminance information only. If a square-wave grating consists of differently colored but brightness-matched stripes, no turning is elicited \citep{Yamaguchi:2008aa}.

\subsection{Neural correlates}
% \subsubsection{Retina}
% \subsubsection{Lamina}
% \subsubsection{Medulla}
% \subsubsection{Lobula complex}
% \subsubsection{Downstream processing}

\section{Algorithmic models of motion detection}
What is required before one can reasonably claim to understand any given system? A popular answer---particularly in the tradition of cybernetics---comes in the form of modeling, the process of building artificial mechanisms that emulate the computations and behaviors accomplished by real brains. If we can replicate what any given neural circuit is doing, and ideally do so quantitatively, substantial progress toward understanding has been made. Models then allow us to isolate minimally required elements, explain existing variance, and predict new results, thus driving subsequent experimental work. They come in many forms, ranging from the simplified and abstract (such as regression or filters) to the complex and concrete (such as biophysical cell models or wide and deep neural networks).

\citet{Yamins:2016hg} identify three qualities that models of sensory systems should possess:
\begin{itemize}
    \item Stimulus-computability: the ability to accept arbitrary stimuli within the relevant domain
    \item Mappability: an internal structure that can be compared to neural circuitry
    \item Predictivity: the ability to compute output for individual stimuli, particularly ones not seen during model fitting
\end{itemize}
While formulated in the context of visual cortical processing, I argue that these demands apply to sensory models in general. Of course, an additional constraint comes from simplicity. If possible, models ought to be as intricate as necessary but no more. With increasing numbers of parameters and general unwieldiness, models run the risk of over-fitting particular data sets and lose their ability to pinpoint critical computational principles \citep[for an example of a large-scale model with limited explanatory value, see][]{Markram:2015aa}. 

Motion vision offers a noteworthy example of productive interplay between experiments and modeling. Early attempts at explaining the psychophysics of motion perception in a connectivist model can be traced back to \citet{Exner:1894aa}. However, his circuit scheme was quantitative only in the vaguest sense. \citet{Hassenstein:1956fa} then made the crucial step toward an algorithmic description of motion processing, one that related motion stimulus to graded behavioral responses using the rigorous tools of signal processing theory. Decades of subsequent research have shown that this detector beautifully fulfils the criteria outlined above. In the following section, I review major models for motion detection in the specific context of fly vision.

\subsection{Fundamental requirements}
% Physics of motion
% Motion equation
% Three demands (Reichardt, 1987; antisymmetric 2-graph!)

Motion of objects has a simple physical definition, displacement over time. Velocity is then given by the elementary difference
\begin{equation}
    v = \frac{\mathop{dx}}{\mathop{dt}}
\end{equation}
where $x$ denotes space and $t$ denotes time. Direction is easily extracted by identifying the sign of $v$. If a motion algorithm had access to high-level features like object position, then motion estimation would be a simple task. However, there is strong evidence that animals from fly to primate extract directional signals directly from simple luminance signals \citep{Borst:2011bq,Adelson:1985tx}.

An interesting static approach comes from Fourier analysis of motion \citep{vanSanten:1985ug}. For any rigidly translating one-dimensional image, the amplitude spectrum of the space-time representation consists of a single line through the origin. Its slope is fully determined by the velocity of the translation. The logic naturally extends to two-dimensional input. A system that has full access to the spatio-temporal history of the visual stimulus could feasibly retrieve motion by measuring the parameters of this line. Such a computation has indeed been suggested for computer vision applications \citep{Heeger:1987ti}. However, it seems obviously implausible for simple nervous systems like that of a fly which transform continuous input and do so instantaneously.

The geometry of motion dictates some basic requirements that any such biologically implementable detector must satisfy \citep{Borst:1989vp}:

\begin{enumerate}
    \item Signals have to be sampled at a minimum of two spatial locations. Any input from one location (which \citet{Reichardt:1987uo} calls a 1-input graph), is inherently ambiguous with regard to direction.
    \item The two signals have to be processed asymmetrically. If the detector is mirror-symmetrical, flipping the stimulus along the axis of motion has no effect on the output even though the direction reverses.
    \item The input signals have to be combined in a non-linear fashion. Linear motion filters can be constructed and do function under certain constraints \citep[see for instance][]{Watson:1985tl}. In general, however, they fail to model empirical direction-selectivity as their time-averaged output is equivalent to the time-averaged input signals, thereby discarding critical information about stimulus sequence.
\end{enumerate}

In the next part, I discuss the two major classes of motion algorithms that fulfil the outlined criteria.

\subsection{Gradient detectors}
If one has access to a local gradient of luminance $I$ in space $x$ and time $t$, assuming a one-dimensional stimulus, velocity is readily obtained from the relation
\begin{equation}
    \frac{\mathop{dI}}{\mathop{dt}} = \frac{\mathop{dI}}{\mathop{dx}} \frac{\mathop{dx}}{\mathop{dt}}
\end{equation}
through simple division of the temporal gradient by the spatial gradient. The scheme was first described in the context of computer vision \citep{Limb:1975aa,Fennema:1979aa} and has several appealing properties. For instance, its output is proportional to local and instantaneous velocity and does not depend on geometrical properties of the stimulus like pattern wavelength or contrast. Moreover, for a fixed-velocity stimulus the estimate is constant in time. Several studies have successfully applied this detector model to the study of biological motion vision \citep{Hildreth:1987jt,Johnston:1995aa,Borst:2007gz}.

It is of course unlikely that biological realizations of the gradient detector compute fully localized derivatives. Neurally plausible models of the gradient detector commonly estimate the spatial derivative as a finite difference between two luminance-sensitive receptors sampling spatially displaced image locations, and then approximate temporal differentiation through mean adaptation as realized by, say, a basic high-pass filter \citep{Srinivasasn:1990aa,Borst:2011bq}.

To operate effectively, the detector clearly requires robust approximations of the luminance gradient. A divisive non-linearity confers several advantages, such as invariance to stimulus contrast, but fails under challenging stimulus conditions. For instance, if pattern contrast is low, spatial derivatives may approach zero and cause the velocity estimate to either amplify random fluctuations of the temporal gradient or even be undefined. For vision, the problem is exacerbated by the Poisson statistics of photon incidence. Such "shot noise" makes photoreceptor output unreliable under low-light conditions \citep{Laughlin:1996aa}. Simulations indicate that for input conditions dominated by noise, the information rate of gradient detectors drops dramatically \citep{Borst:2007gz}.

Some formulations of the model circumvent the issue by using non-linearities that are less dependent on stable estimates of the gradient, like the logical veto gate put forward by \citet{Marr:1981aa}. \citet{Potters:1994aa} suggested that motion vision should only be mediated by gradient detectors in the regime of large signal-to-noise ratios. If stimuli are noisy, more robust algorithms like the correlation detector described below ought to be preferred. Counter to this dual-mechanism postulate, \citet{Haag:2004bj} could show that blowfly motion vision exhibits all the hallmarks of correlation-based schemes across a wide range of pattern luminance. Optimal trade-off between mechanisms was not observed.

\subsection{Correlation detectors}
% Implementations: Reichardt detector, Barlow-Levick
% Elaborations & alternative formulations
% ON/OFF - cite Joesch (2013)
% Mention Borst et al., 2005
% Cite Borst & Egelhaaf on AM
% Cite Lei
% Explains spatial aliasing

Correlation detectors represent the predominant class of motion extraction models used in sensory neuroscience. They have been successfully employed to explain properties of motion vision across the full spectrum, from psychophysics and animal behavior down to physiological responses of direction-selective cells.

Fundamentally, the algorithm is based on the temporally delayed comparison of two spatially separated visual inputs. This lines up well with physical intuitions about motion. When an object moves from one location to the next, we observe a visual match across time and space. A bright dot moving from left to right, for instance, produces first a positive deflection in the output of the leftmost photoreceptor and then, after a time determined by the object's velocity, a positive deflection in the adjacent rightward location. In a sense, motion detection then reduces to the task of determining the temporal sequence of these two visual events. The logic conveniently extends to continuous luminance signals. By isolating slanted spatiotemporal correlations, one can compute the direction and magnitude of motion from locally sampled brightness input. The operation then closely resembles cross-correlation of two spatially separated inputs \citep{Reichardt:1987uo}.

\subsubsection{Reichardt detector}

The first quantitative description of a correlation-type motion detector was derived from optomotor behavior in \textit{Chlorophanus viridis} walking on a Y-maze \citep{Hassenstein:1951aa}. The textured rotating drum could only be observed through two separated slits, so the stimulus consisted of two spatially and temporally isolated brightness changes akin to apparent motion \citep{Wertheimer:1912aa}. Hassenstein showed that the beetle would robustly turn with pattern motion if the events had the same contrast polarity. That is, combinations of either bright (ON) or dark (OFF) elicited syndirectional turning. However, for mixed-polarity sequences (ON-OFF or OFF-ON) turning was inverted. This stimulus is closely related to the psychophysical phenomenon of reverse-phi \citep{Anstis:1970tv,Anstis:1975tu}. When \citet{Hassenstein:1956fa} varied spatial and temporal separation of the flashes, they found clear optima. Specifically, the optimal distance was approximately equivalent to beetle's inter-ommatidial distance.

A critical insight for model building came from the analogy to the rules of sign-correct multiplication. Equally signed products are positive, mixed products negative. This led to the development of what is interchangeably called Hassenstein-Reichardt correlator, Reichardt detector, or elementary motion detector \citep{Reichardt:1961aa}. It computes local motion and can operate directly on continuous luminance signals, thus processing arbitrary visual inputs.

In its basic form, the detector consists of two mirror-symmetrical subunits. Each receives visual input from two distinct points in visual space, separated by the sampling distance $\Delta\phi$, one of which is then delayed with respect to the other. This processing step can take many forms, including a true delay, but is often implemented as a first- or second-order linear temporal filter. Such low-pass filters produce a phase shift that effectively delays arbitrary time-varying signals. Subsequently, the two signals are multiplied.

The combination of filtering and multiplication implements the delay-and-compare algorithm described above: if $\Delta\phi$ and the time constant of the delay filter are matched to the direction and velocity of the traveling object, two signal deflections will coincide at the multiplier and give rise to a large signal. This happens only when the object first passes the delayed line, therefore moving along the preferred direction of the subunit. Conversely, if the object moves in the opposite (or null) direction, the excitations are mistimed and produce small or no output. Finally, the output signals of the two oppositely tuned subunits are subtracted which results in fully opponent direction-selective detector that responds positively for its preferred and negatively for its null direction. Additionally, the subtraction stage suppresses signals produced by motion-unrelated visual cues like static illumination or full-field flicker. Under the assumption that each ommatidium provides one such input signal, the algorithm parsimoniously explains the aforementioned findings on optomotor responses in the beetle. In particular, it predicts the inversion that occurs when negative and positive contrast are combined in appropriately tuned spatial and temporal succession. Its architecture also adheres to the three criteria listed in the previous section, with multiplication supplying the non-linearity \citep{Borst:1989vp}.

Any elementary motion detector is only sensitive to motion within the small part of the visual field defined by nearest-neighbor interactions of inputs. To generate the behavioral optomotor response, \citet{Hassenstein:1956fa} proposed that a large array of detectors is spatially integrated. When stimulated with periodic sine gratings traveling at a fixed velocity, individual detectors produce sinusoidally modulated output. Direction is encoded in the offset or temporal mean of the response. After summation, responses still show some initial oscillations. However, the steady-state response does not vary with time. The length of this modulated period is determined by the filter time constants of the input lines \citep{Egelhaaf:1989wf,Egelhaaf:1989wd}.

Depending on the particular model in question, a different filter configuration may apply; some instantiations have a peripheral high-pass filter in both arms, some only in the non-delayed line, and others only use a single low-pass filter in the delayed line. Qualitatively, their response properties are similar \citep{Borst:2003bz}.

For specific forms of the Reichardt detector the steady-state frequency optimum can be calculated analytically. Consider a simple model that has a first-order linear low-pass filter with time constant $\tau$ in the delayed arm and passes the signal unfiltered in the direct line. The time- and space-averaged steady-state response of the array is then given by
\begin{equation}
    R = {\Delta I}^2 \sin(2 \pi \frac{\Delta\phi}{\lambda}) \frac{\tau \omega}{1 + \tau^2 \omega^2}
\end{equation}
where $\mathop{\Delta I}$ denotes grating contrast, $\lambda$ the spatial wavelength of the pattern, and $\omega$ the circular stimulus frequency $2 \pi f$ \citep{Borst:2003bz}.

From this, we can see that Reichardt detector arrays neatly recapitulate the fundamental tuning properties of the grating-induced \textit{Drosophila} optomotor response \citep{Gotz:1964bj} as well as functional properties of tangential cells \citep{Joesch:2008fo}:

\begin{enumerate}
    \item The sign of the response depends on the direction of the moving pattern.
    \item The velocity tuning hinges critically on the spatial wavelength of the pattern, and the detector is tuned to temporal frequency $\frac{v}{\lambda}$.
    \item The frequency tuning has an optimum.
    \item When the stimulus is under-sampled, responses invert (as indicated by the $\Delta\phi$-dependent geometric interference term). Setting the sampling base to the inter-ommatidial angle reproduces empirically found aliasing, supporting the notion that the fly visual system extracts motion from local interactions.
    \item Responses increase quadratically with contrast due to the multiplication stage.
\end{enumerate}

The close match between a model initially derived from beetle behavior and fly vision data suggests that insects share the basic algorithms underlying motion detection. Correlation-based algorithms appear to be a fundamental solution for the problem of determining spatiotemporal sequence.

In contrast to gradient detection strategies and due to the properties of multiplication, Reichardt correlators are quite robust to spatial gradients that approach zero as well as tolerant of degraded input. The detector's output carries substantial information about motion direction and magnitude even in the presence of strong Poisson noise \citep{Borst:2007gz,Shi:2006du}. This comes at the cost of output that strongly depends on unrelated properties of the pattern and is approximately proportional to velocity only within a limited range. Note, however, that for naturalistic image sets, the output of the Reichardt detector becomes a more reliable read-out for scene velocity \citep{Dror:2000cr,Dror:2001wc}.

\subsubsection{Motion energy detectors}
Research on vertebrate vision, including psychophysics in humans, has given rise to the so-called motion energy model of direction-selectivity \citep{Adelson:1985tx,vanSanten:1984wg}. It involves the construction of spatiotemporally oriented filters that operate on luminance signals. When viewed across space and time, moving images exhibit a characteristic tilt whose angle of course depends on direction and velocity. An appropriately tilted filter is then sensitive to image motion that matches its receptive field.

In practice, the approach makes use of an elegant trick to create such filters from non-tilted receptive fields. By combining appropriate one-dimensional filters in space and time, one can create odd and even receptive fields that are linearly separable. Summing them in various combinations yields inseparable, spatiotemporally oriented linear filters. Input sequences are convolved with this set of kernels, squared, and finally summed. The resulting output is selective for direction and explains significant aspects of motion phenomenology.

Interestingly, with mild assumptions about the peripheral filters, the motion energy model can be proven equivalent to the Reichardt detector \citep{vanSanten:1985ug}. The product of differentially delayed signals, as it is calculated in the Hassenstein-Reichardt scheme, reappears in the output of the algorithm proposed by \citet{Adelson:1985tx}. Response properties derived for one therefore generally apply to the other. Both are examples of the more general delay-and-compare strategy. Note, however, that internal structure and intermediate representations differ between the two.

% Talk about phase delay

\subsubsection{Barlow-Levick detector}
Following physiological investigations in the rabbit retina, \citet{Barlow:1965aa} proposed a cognate algorithm for motion sensitivity that has been particularly influential in studies on the vertebrate retina \citep{Borst:2015ko}. Their model is structured like an isolated Reichardt detector subunit; again, two spatially displaced inputs are compared after one of them is delayed. Instead of multiplication, however, the detector uses a veto gate. If two signals reach the non-linear stage at the same time, no output is produced. Otherwise, signals pass through. While subunits in a Reichardt detector amplify responses to motion in their preferred direction, Barlow-Levick detectors suppress signals elicited by motion in their null direction. 

Reichardt and Barlow-Levick detectors with identical preferred direction thus differ in the type of non-linearity they employ (amplifying versus inhibitory) as well as the placement of the temporal delay (on the arm passed first by a preferred stimulus versus the second). From a functional perspective, however, their characteristics are strikingly similar.

\subsubsection{Elaborated architectures}
Most models described so far were initially designed as blackbox approximations of stimulus-response relationships. Circuit neuroscience is of course interested in the correspondence of algorithm and implementation---which neural elements perform the individual computations that make up the detector model? In the interest of mappability, we may be interested in neurons that act as direct and delayed line or the biophysics that govern the non-linearity of a Reichardt detector. In this section, I give some examples of elaborated detector architectures that provide closer fits with either empirical data or biological substrate.

% Adaptation: Cite Harris, Borst

A typical complication, for instance, concerns peripheral receptor elements. At their most basic, these are samples from a single point in the image plane. This model of the optic properties is of course insufficient. Real ommatidia have acceptance angles that are well approximated by a Gaussian with a half-width at maximum of $\approx \SI{5}{\degree}$ in the case of \textit{D. melanogaster} \citep{Goetz:1965aa}. Real-world simulations thus often apply appropriate spatial blurring at the input.

More complex modifications were put forward based on experimental findings that responses of direction-selective fly tangential cells are subject to velocity-specific motion adaptation \citep{Harris:1999kj}. Moreover, in a dynamic regime, H1 of \textit{Calliphora vicina} adjusts its coding range depending on the velocity distribution of the motion stimulus \citep{Brenner:2000aa,Fairhall:2001aa}. Some models postulated adaptation of the Reichardt detector time constant in order to account for these effects. Intriguingly, however, even the unmodified model with fixed $\tau$ provides gain control and expands or contracts its coding range in accord with the stimulus distribution \citep{Borst:2005dr}.

A breakthrough in understanding of peripheral motion processing in the fruit fly came with the discovery that direction-selectivity is computed in parallel bright- and dark-processing channels \citep{Joesch:2010fw}, similarly to the mammalian retina \citep{Borst:2015ko}. Silencing the L1 or L2 pathway led to a loss of motion-sensitivity in tangential cells that was specific to bright (ON) or dark (OFF) edges, respectively. Moreover, calcium imaging from L2 terminals had revealed approximately half-wave rectified responses to luminance steps \citep{Reiff:2010eo}.

The internal structure of a classical Reichardt detector does not take the ON-OFF distinction into account. Input signals are free to vary between positive and negative, and the non-linear stage is a simple mathematical operation. Interestingly, half-wave rectification have previously been suggested in the context of biophysically plausible sign-correct multiplication. By splitting the incoming signal into its positive and negative components, multiplying the four quadrants (ON-ON, OFF-OFF, ON-OFF, and OFF-ON) individually, and summing them with appropriate signs, multiplication could be realized without having to postulate synaptic machinery capable of performing the operation in one step.

Physiological findings hinted that the fly motion detection system consists of only two same-sign quadrants. However, it is well established that both optomotor response and tangential cells exhibit inverted sensitivity to apparent motion sequences that consist of mixed ON and OFF steps (closely related to so-called reverse-phi stimuli) \citep{Hassenstein:1956fa,Egelhaaf:1992wh,Clark:2011gw}. \citet{Eichner:2011ic} constructed an elaborated Reichardt detector that was able to reconcile the findings. It consists of two Reichardt detectors, each of which processes either positive or negative luminance changes. Pre-processing is modeled as a differentiation-approximating high-pass filter whose output is half-wave rectified to generate either an ON or an OFF signal. Critically, this high-pass signal is summed with a small tonic luminance contribution (DC) before rectification, which simulates lamina processing and renders the separation between ON and OFF somewhat leaky. Signals are then fed into regular Reichardt detectors. At the end, ON and OFF units are added to yield the final output.

The resulting model faithfully reproduces the hallmarks of similarly tuned classical correlation models such as temporal frequency tuning. Interestingly, due to the DC component and resulting border effects it does produce inverted output for apparent motion steps that involve mixed polarities even though ON and OFF components are not directly multiplied. Moreover, the elaborated model could successfully predict that for non-overlapping apparent motion flashes in both \textit{Calliphora} and \textit{Drosophila}, only same-sign combinations would elicit responses \citep[see also][]{Franceschini:1989aa}. By aiming for biological plausibility in its internal structure, the model gained in predictive power.

A related study used genetic silencing of L1 and L2 to study similar reverse-phi responses in walking fruit flies \citep{Clark:2011gw}. To explain their findings, they proposed an alternative model that computes six combinations of positive or negative signal contrast and sums them with differential weights. A subsequent investigation of reverse-phi responses in tangential cells combined their measurements with genetic silencing of L1 and L2. For all stimulus configurations, the two-quadrant detector performed better than its six-quadrant counterpart \citep{Joesch:2013ew}.

% Quadrants for biophysical plausibility
% Algorithm for rectification

% \subsubsection{Neural implementation}
% % Cite Koch
% % Mo & Koch, Torre & Poggio, Srinivasan (1976)

% % Talk about why RD may be GOOD ENOUGH for closed-loop control

% % WRITE ABOUT VOLTERRA EXPANSION

% \section{Tools for Drosophila circuit neuroscience}
% \subsection{Neurogenetics}
% \subsection{Behavioral assays}
% % % Free flight
% \subsection{Electrophysiology}
% \subsection{Imaging techniques}
% \subsection{Connectivity analysis}

% \section{Concluding remarks}

% TALK ABOUT OTHER MODALITIES
% Intro: Drosophila puzzles together a picture of its surround, task of systems neuroscience, cybernetics